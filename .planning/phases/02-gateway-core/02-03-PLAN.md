---
phase: 02-gateway-core
plan: 03
type: execute
wave: 3
depends_on: ["02-02"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "User can connect to the gateway via WebSocket and send a message that returns a streaming response from an LLM (Anthropic initially)"
    - "Gateway creates isolated sessions per agent with transparent session keys visible to the user"
    - "User can view the full assembled context (system prompt, memory, skills, history, tools) before it is sent to the model"
    - "Context inspector displays byte count, token count, and cost estimate for each context section"
    - "Gateway tracks and displays token usage and cost per request with running totals per model"
  artifacts: []
  key_links: []
---

<objective>
End-to-end verification of the complete Phase 2 gateway: streaming chat, session isolation, context inspection, and usage tracking.

Purpose: Confirm all five Phase 2 success criteria are met before marking the phase complete.
Output: Human-verified gateway functionality.
</objective>

<execution_context>
@/Users/hitekmedia/.claude/get-shit-done/workflows/execute-plan.md
@/Users/hitekmedia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-gateway-core/02-01-SUMMARY.md
@.planning/phases/02-gateway-core/02-02-SUMMARY.md
</context>

<tasks>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 1: Verify complete Phase 2 gateway end-to-end</name>
  <files>packages/gateway/dist/index.js</files>
  <action>
Human verification of the complete Phase 2 gateway. All code was built in Plans 02-01 and 02-02. This checkpoint verifies the integrated experience works correctly.

What was built: Complete WebSocket gateway with streaming LLM responses (Anthropic Claude via AI SDK 6), session management with transparent keys (agent:default:{id}), context inspection with byte/token/cost per section, usage tracking with per-model running totals, concurrent stream protection, and error handling for missing keys, invalid sessions, and malformed messages.

**Prerequisites:** Ensure an Anthropic API key is in the vault (`agentspace keys list` should show anthropic).

**Start the gateway:**
```bash
cd /Users/hitekmedia/Documents/GitHub/AgentSpace
pnpm --filter @agentspace/gateway exec tsx src/index.ts
```

**In a second terminal, connect via wscat:**
```bash
npx wscat -c ws://127.0.0.1:3271/gateway
```

**Test 1 -- Streaming chat (Success Criteria 1):**
Send: `{"type":"chat.send","id":"t1","content":"What is 2+2? Reply in one sentence."}`
Expected:
- Receive `session.created` with sessionId and sessionKey (format: agent:default:...)
- Receive `chat.stream.start` with model: claude-sonnet-4.5
- Receive multiple `chat.stream.delta` messages with text chunks
- Receive `chat.stream.end` with usage (inputTokens > 0, outputTokens > 0) and cost (totalCost > 0)

**Test 2 -- Session isolation (Success Criteria 2):**
Note the sessionId from Test 1.
Send: `{"type":"chat.send","id":"t2","content":"What was my previous question?","sessionId":"SESSION_ID_FROM_T1"}`
Expected: Response references "2+2" (proves session history is maintained).
Send: `{"type":"chat.send","id":"t3","content":"Hello"}`  (no sessionId)
Expected: NEW session.created with different sessionId/sessionKey. Response does NOT reference "2+2".

**Test 3 -- Context inspection (Success Criteria 3 and 4):**
Send: `{"type":"context.inspect","id":"t4","sessionId":"SESSION_ID_FROM_T1"}`
Expected:
- Receive `context.inspection` with sections array containing: system_prompt, history, memory, skills, tools
- Each section has: name, content, byteCount (number), tokenEstimate (number), costEstimate (number)
- system_prompt content is "You are a helpful AI assistant."
- history content contains the previous messages from Test 1 and 2
- memory, skills, tools have byteCount: 0 (stubs)
- totals object with summed byteCount, tokenEstimate, costEstimate

**Test 4 -- Usage tracking (Success Criteria 5):**
Send: `{"type":"usage.query","id":"t5"}`
Expected:
- Receive `usage.report` with perModel containing an entry for claude-sonnet-4.5
- Entry shows inputTokens > 0, outputTokens > 0, totalCost > 0, requestCount >= 2
- grandTotal shows aggregate totals

**Test 5 -- Session listing:**
Send: `{"type":"session.list","id":"t6"}`
Expected: At least 2 sessions listed (from Test 1 and Test 2).

**Test 6 -- Error handling:**
Send: `{"type":"chat.send","id":"t7","content":"test","sessionId":"nonexistent"}`
Expected: Error with code SESSION_NOT_FOUND.
Send: `not valid json`
Expected: Error with code INVALID_MESSAGE or PARSE_ERROR.

**Test 7 -- Concurrent stream protection:**
While a long response is streaming, send another chat.send on the same connection.
Expected: Error with code STREAM_IN_PROGRESS.
  </action>
  <verify>All 7 tests pass. Human confirms streaming responses arrive, sessions are isolated, context inspection shows sections with measurements, usage tracking reports totals, and error handling works correctly.</verify>
  <done>All 5 Phase 2 success criteria verified by human tester. Phase 2 is complete and ready for Phase 3 (CLI Interface).</done>
</task>

</tasks>

<verification>
All 5 Phase 2 success criteria verified by human tester:
1. WebSocket connection + streaming LLM response works
2. Session isolation with transparent keys works
3. Context inspection shows full assembled context
4. Context inspector includes byte/token/cost per section
5. Usage tracking with per-model running totals works
</verification>

<success_criteria>
- Human confirms all 7 verification tests pass
- Phase 2 is complete and ready for Phase 3 (CLI Interface)
</success_criteria>

<output>
After completion, create `.planning/phases/02-gateway-core/02-03-SUMMARY.md`
</output>
